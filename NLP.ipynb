{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb_data():\n",
    "    from keras.datasets import imdb\n",
    "    (train_data, train_labels), (test_data, test_labels) = imdb.load_data()\n",
    "\n",
    "    word_index = imdb.get_word_index()\n",
    "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "    train_reviews = [' '.join([reverse_word_index.get(i - 3, '?') for i in review]) for review in train_data]\n",
    "    test_reviews = [' '.join([reverse_word_index.get(i - 3, '?') for i in review]) for review in test_data]\n",
    "\n",
    "    train_df = pd.DataFrame({\"review\": train_reviews, \"label\": train_labels})\n",
    "    test_df = pd.DataFrame({\"review\": test_reviews, \"label\": test_labels})\n",
    "\n",
    "    return pd.concat([train_df, test_df]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_genres(movie_id):\n",
    "    ia = IMDb()\n",
    "    movie = ia.get_movie(movie_id)\n",
    "    return movie.get('genres', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(row):\n",
    "    keywords = {\n",
    "        \"funny\": [\"funny\", \"hilarious\", \"comedy\", \"humor\", \"laugh\"],\n",
    "        \"scary\": [\"scary\", \"horror\", \"terrifying\", \"frightening\", \"creepy\"],\n",
    "        \"bad\": [\"bad\", \"terrible\", \"awful\", \"poor\", \"waste\"],\n",
    "        \"good\": [\"good\", \"great\", \"excellent\", \"amazing\", \"wonderful\"],\n",
    "        \"dramatic\": [\"dramatic\", \"emotional\", \"heartbreaking\", \"moving\", \"touching\"]\n",
    "    }\n",
    "\n",
    "    label_counts = {label: 0 for label in keywords.keys()}\n",
    "    review_text = row[\"review\"].lower()\n",
    "\n",
    "    for label, words in keywords.items():\n",
    "        if any(word in review_text for word in words):\n",
    "            label_counts[label] += 1\n",
    "    \n",
    "    return max(label_counts, key=label_counts.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_genre(reviews_df, specific_genre):\n",
    "    filtered_data = reviews_df[reviews_df[\"movie_id\"].apply(lambda x: specific_genre in get_movie_genres(x))]\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = load_imdb_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data['label'] = imdb_data.apply(label_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific_genre = \"Horror\"\n",
    "# filtered_data = filter_by_genre(imdb_data, specific_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the data\n",
    "# filtered_data[\"labels\"] = filtered_data.apply(label_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered and labeled data to a new CSV file\n",
    "imdb_data.to_csv(\"filtered_labeled_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([imdb_data, pd.get_dummies(imdb_data['label'], prefix='label')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=['label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Join words back into a string\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review'] = train_df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'film brilliant casting location scenery story direction everyone really suited part played could imagine robert redford amazing actor director norman father came scottish island loved fact real connection film witty remark throughout film great brilliant much bought film soon released retail would recommend everyone watch fly fishing amazing really cried end sad know say cry film must good definitely also congratulation two little boy played part norman paul brilliant child often left praising list think star play grown big profile whole film child amazing praised done think whole story lovely true someone life shared u'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "279/279 [==============================] - 172s 607ms/step - loss: 1.2760 - accuracy: 0.4714 - val_loss: 1.0720 - val_accuracy: 0.5430\n",
      "Epoch 2/5\n",
      "279/279 [==============================] - 177s 634ms/step - loss: 0.8528 - accuracy: 0.6809 - val_loss: 0.6146 - val_accuracy: 0.7464\n",
      "Epoch 3/5\n",
      "279/279 [==============================] - 196s 701ms/step - loss: 0.5962 - accuracy: 0.7713 - val_loss: 0.4700 - val_accuracy: 0.8107\n",
      "Epoch 4/5\n",
      "279/279 [==============================] - 193s 691ms/step - loss: 0.4209 - accuracy: 0.8520 - val_loss: 0.4442 - val_accuracy: 0.8273\n",
      "Epoch 5/5\n",
      "279/279 [==============================] - 200s 717ms/step - loss: 0.3052 - accuracy: 0.9092 - val_loss: 0.2411 - val_accuracy: 0.9345\n",
      "310/310 [==============================] - 24s 79ms/step - loss: 0.2383 - accuracy: 0.9373\n",
      "Test accuracy: 93.73%\n"
     ]
    }
   ],
   "source": [
    "# Define the number of classes\n",
    "num_classes = 5\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_df['review'])\n",
    "sequences = tokenizer.texts_to_sequences(train_df['review'])\n",
    "\n",
    "# Pad the sequences to have the same length\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "labels = pd.get_dummies(train_df[['label_bad', 'label_dramatic', 'label_funny', 'label_good', 'label_scary']])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(0.8 * len(train_df))\n",
    "train_data = padded_sequences[:train_size]\n",
    "train_labels = labels[:train_size].values\n",
    "test_data = padded_sequences[train_size:]\n",
    "test_labels = labels[train_size:].values\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=32))\n",
    "model.add(LSTM(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, validation_split=0.1, epochs=5, batch_size=128)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_data, test_labels)\n",
    "print(\"Test accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 26s 83ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.98      0.98      0.98      2187\n",
      "    dramatic       0.00      0.00      0.00       139\n",
      "       funny       0.89      0.99      0.94      4449\n",
      "        good       0.98      0.84      0.90      2310\n",
      "       scary       0.99      0.96      0.97       831\n",
      "\n",
      "    accuracy                           0.94      9916\n",
      "   macro avg       0.77      0.75      0.76      9916\n",
      "weighted avg       0.93      0.94      0.93      9916\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get the model's output probabilities for each class\n",
    "probs = model.predict(test_data)\n",
    "\n",
    "# Get the predicted class for each sample\n",
    "pred_classes = np.argmax(probs, axis=1)\n",
    "\n",
    "# Get the true class for each sample\n",
    "true_classes = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Get the classification report for each class\n",
    "target_names = ['bad', 'dramatic', 'funny', 'good', 'scary']\n",
    "print(classification_report(true_classes, pred_classes, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "279/279 [==============================] - 174s 614ms/step - loss: 1.3264 - accuracy: 0.4601 - val_loss: 1.0668 - val_accuracy: 0.5306\n",
      "Epoch 2/5\n",
      "279/279 [==============================] - 175s 627ms/step - loss: 0.9024 - accuracy: 0.6862 - val_loss: 0.6464 - val_accuracy: 0.7860\n",
      "Epoch 3/5\n",
      "279/279 [==============================] - 190s 679ms/step - loss: 0.5900 - accuracy: 0.8299 - val_loss: 0.5712 - val_accuracy: 0.8112\n",
      "Epoch 4/5\n",
      "279/279 [==============================] - 189s 678ms/step - loss: 0.3798 - accuracy: 0.9089 - val_loss: 0.2435 - val_accuracy: 0.9430\n",
      "Epoch 5/5\n",
      "279/279 [==============================] - 190s 682ms/step - loss: 0.2271 - accuracy: 0.9543 - val_loss: 0.1549 - val_accuracy: 0.9682\n",
      "310/310 [==============================] - 21s 67ms/step - loss: 0.1556 - accuracy: 0.9675\n",
      "Test accuracy: 96.75%\n",
      "310/310 [==============================] - 26s 82ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.99      0.98      0.98      2187\n",
      "    dramatic       0.50      0.01      0.01       139\n",
      "       funny       0.95      0.99      0.97      4449\n",
      "        good       0.98      0.97      0.98      2310\n",
      "       scary       0.97      0.97      0.97       831\n",
      "\n",
      "    accuracy                           0.97      9916\n",
      "   macro avg       0.88      0.78      0.78      9916\n",
      "weighted avg       0.96      0.97      0.96      9916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=10000, output_dim=32))\n",
    "model2.add(LSTM(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model2.add(Dense(units=num_classes, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define the class weights\n",
    "# Convert the labels to one-hot encoding\n",
    "label_names = ['label_bad', 'label_dramatic', 'label_funny', 'label_good', 'label_scary']\n",
    "labels = pd.get_dummies(train_df[label_names])\n",
    "class_weights = {i: 1 for i in range(num_classes)}\n",
    "class_weights[label_names.index('label_dramatic')] = 2\n",
    "# Train the model with the class weights\n",
    "model2.fit(train_data, train_labels, validation_split=0.1, epochs=5, batch_size=128, class_weight=class_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model2.evaluate(test_data, test_labels)\n",
    "print(\"Test accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Calculate the per-class metrics\n",
    "probs = model2.predict(test_data)\n",
    "pred_classes = np.argmax(probs, axis=1)\n",
    "target_names = ['bad', 'dramatic', 'funny', 'good', 'scary']\n",
    "print(classification_report(np.argmax(test_labels, axis=1), pred_classes, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
